{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42940f62",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29f71df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.1\r\n"
     ]
    }
   ],
   "source": [
    "! mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9750ffb",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919a86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d989795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-29 19:25:11--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.78.182\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.78.182|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1333519 (1.3M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2021-01.parquet’\n",
      "\n",
      "green_tripdata_2021 100%[===================>]   1.27M  --.-KB/s    in 0.03s   \n",
      "\n",
      "2022-05-29 19:25:11 (40.8 MB/s) - ‘green_tripdata_2021-01.parquet’ saved [1333519/1333519]\n",
      "\n",
      "--2022-05-29 19:25:11--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-02.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.78.182\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.78.182|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1145679 (1.1M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2021-02.parquet’\n",
      "\n",
      "green_tripdata_2021 100%[===================>]   1.09M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2022-05-29 19:25:11 (89.8 MB/s) - ‘green_tripdata_2021-02.parquet’ saved [1145679/1145679]\n",
      "\n",
      "--2022-05-29 19:25:11--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-03.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.78.182\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.78.182|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1474538 (1.4M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2021-03.parquet’\n",
      "\n",
      "green_tripdata_2021 100%[===================>]   1.41M  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-05-29 19:25:11 (82.6 MB/s) - ‘green_tripdata_2021-03.parquet’ saved [1474538/1474538]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\n",
    "! wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-02.parquet\n",
    "! wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-03.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "749399f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv green_tripdata_2021-01.parquet data/green_tripdata_2021-01.parquet\n",
    "! mv green_tripdata_2021-02.parquet data/green_tripdata_2021-02.parquet\n",
    "! mv green_tripdata_2021-03.parquet data/green_tripdata_2021-03.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3455b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python homework/preprocess_data.py --raw_data_path ./data --dest_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf647cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv.pkl\ttest.pkl  train.pkl  valid.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a83fb3",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ddbb7",
   "metadata": {},
   "source": [
    "#### Source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a555057",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ubuntu/.local/share/jupyter/runtime/kernel-676cae7a-4b77-40d1-970b-974f48509a17.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp-tracking-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run(data_path):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "    rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_valid)\n",
    "\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c55e2",
   "metadata": {},
   "source": [
    "#### With mlfow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03710646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/29 19:40:53 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-homework' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', experiment_id='2', lifecycle_stage='active', name='nyc-taxi-homework', tags={}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-homework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "739c5583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='./mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/2', experiment_id='2', lifecycle_stage='active', name='nyc-taxi-homework', tags={}>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a23098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run(experiment_id: int, developer: str, data_path: str):\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "        \n",
    "        mlflow.set_tag(\"developer\", developer)\n",
    "\n",
    "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "        X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_valid)\n",
    "\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "        \n",
    "        \n",
    "run(\"2\", \"Andrei\", \"./output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c08a06",
   "metadata": {},
   "source": [
    "- Parameters (17)\n",
    "\n",
    "Name\tValue\n",
    "\n",
    "bootstrap\tTrue\n",
    "\n",
    "ccp_alpha\t0.0\n",
    "\n",
    "criterion\tsquared_error\n",
    "\n",
    "max_depth\t10\n",
    "\n",
    "max_features\t1.0\n",
    "\n",
    "max_leaf_nodes\tNone\n",
    "\n",
    "max_samples\tNone\n",
    "\n",
    "min_impurity_decrease\t0.0\n",
    "\n",
    "min_samples_leaf\t1\n",
    "\n",
    "min_samples_split\t2\n",
    "\n",
    "min_weight_fraction_leaf\t0.0\n",
    "\n",
    "n_estimators\t100\n",
    "\n",
    "n_jobs\tNone\n",
    "\n",
    "oob_score\tFalse\n",
    "\n",
    "random_state\t0\n",
    "\n",
    "verbose\t0\n",
    "\n",
    "warm_start\tFalse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfbf66",
   "metadata": {},
   "source": [
    "- Metrics\n",
    "\n",
    "Name\tValue\n",
    "\n",
    "training_mae\t3.958\n",
    "\n",
    "training_mse\t32.84\n",
    "\n",
    "training_r2_score\t0.754\n",
    "\n",
    "training_rmse\t5.731\n",
    "\n",
    "training_score\t0.754"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a15f3d",
   "metadata": {},
   "source": [
    "#### Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec174bbd",
   "metadata": {},
   "source": [
    "default-artifact-root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d5730",
   "metadata": {},
   "source": [
    "#### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63ceac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hpo_mlflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hpo_mlflow.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run(data_path, num_trials):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag(\"model\", \"Random Forest Regressor\")\n",
    "            mlflow.log_params(params)\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_valid)\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_evals\",\n",
    "        default=50,\n",
    "        help=\"the number of parameter evaluations for the optimizer to explore.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.max_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a35c34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 50/50 [08:52<00:00, 10.65s/trial, best loss: 6.6284257482044735]\n"
     ]
    }
   ],
   "source": [
    "! python hpo_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810b02e",
   "metadata": {},
   "source": [
    "#### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8c63d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model_hw.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model_hw.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import hp, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-model\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "SPACE = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        params = space_eval(SPACE, params)\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate model on the validation and test sets\n",
    "        valid_rmse = mean_squared_error(y_valid, rf.predict(X_valid), squared=False)\n",
    "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "\n",
    "def run(data_path, log_top):\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # retrieve the top_n model runs and log the models to MLflow\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=log_top,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    for run in runs:\n",
    "        train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "\n",
    "    # select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        filter_string=\"\",\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.test_rmse ASC\"]\n",
    "    )[0]\n",
    "\n",
    "    # register the best model\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "        name=EXPERIMENT_NAME\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--top_n\",\n",
    "        default=5,\n",
    "        type=int,\n",
    "        help=\"the top 'top_n' models will be evaluated to decide which model to promote.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21a5604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/05/31 10:01:01 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-model' does not exist. Creating a new experiment.\n",
      "2022/05/31 10:01:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/anaconda3/envs/exp-tracking-env/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n",
      "Successfully registered model 'random-forest-best-model'.\n",
      "2022/05/31 10:02:49 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: random-forest-best-model, version 1\n",
      "Created version '1' of model 'random-forest-best-model'.\n"
     ]
    }
   ],
   "source": [
    "! python register_model_hw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9346e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='./mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/2', experiment_id='2', lifecycle_stage='active', name='nyc-taxi-homework', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/3', experiment_id='3', lifecycle_stage='active', name='random-forest-hyperopt', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/5', experiment_id='5', lifecycle_stage='active', name='random-forest-best-model', tags={}>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbb7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name('random-forest-best-model')\n",
    "best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        filter_string=\"\",\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.test_rmse ASC\"]\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b568a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(best_run.data.metrics['test_rmse'], 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
